{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Motunrayo244/Datacentric-AI/blob/main/Voxel51/Voxel51_Objectdetection__detection_mistakes_with_detectron_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding Detection Mistakes with FiftyOne using Detectron2 pretrained model for prediction\n",
        "\n",
        "This notebook is an adoption of the tutorial notebook provided by voxel 51 on thei websites for finding detection mistakes.\n",
        "\n",
        "A few changes were made to the default notebook, this is in order to create a standardized the variables for comparism.\n",
        "\n",
        "In this notebook\n",
        "Dataset: The dataset used is downloaded from the 118 sample images provided by cleanlab in their documentation.\n",
        "Model: This notebook used the COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml default model"
      ],
      "metadata": {
        "id": "bWXBg55WurNv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1bmisr8vbf-"
      },
      "source": [
        "# Finding Detection Mistakes with FiftyOne\n",
        "\n",
        "Annotations mistakes create an artificial ceiling on the performance of your models. However, finding these mistakes by hand is at least as arduous as the original annotation work! Enter FiftyOne.\n",
        "\n",
        "In this tutorial, we explore how FiftyOne can be used to help you find mistakes in your object detection annotations. To detect mistakes in classification datasets, check out [this tutorial](https://voxel51.com/docs/fiftyone/tutorials/classification_mistakes.html).\n",
        "\n",
        "We'll cover the following concepts:\n",
        "\n",
        "- Loading your existing dataset [into FiftyOne](https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/index.html)\n",
        "- [Adding model predictions](https://voxel51.com/docs/fiftyone/recipes/adding_detections.html) to your dataset\n",
        "- Computing insights into your dataset relating to [possible label mistakes](https://voxel51.com/docs/fiftyone/user_guide/brain.html#label-mistakes)\n",
        "- Visualizing mistakes in the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html)\n",
        "\n",
        "**So, what's the takeaway?**\n",
        "\n",
        "FiftyOne can help you find and correct label mistakes in your datasets, enabling you to curate higher quality datasets and, ultimately, train better models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qil3F1LHvbgB"
      },
      "source": [
        "## Setup\n",
        "\n",
        "If you haven't already, install FiftyOne:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b3XBj2HsvbgC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install fiftyone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm9LYHEqvtii",
        "outputId": "c88f03c9-752c-4d37-eef6-2627c2ecc0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-gehpsftc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-gehpsftc\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit eb96ee1d4752ff5896f623f738641fba9c755237\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.15.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black (from detectron2==0.6)\n",
            "  Downloading black-24.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.10.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6147646 sha256=d9d15f080ceaa7fa8949ac88a46e6f33568c50cc5e68ef65bd34f3dc906ea0f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kg_vsf5c/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=19cb1eb75d9168062e9749e34dfd56c8688578c79550d94816e2412f2bbebdb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=8226fd30d9eac18d8621872f9f6f3d3940c4756d226073e1301a0b4612a4d025\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-24.3.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.8.2 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "! python -m pip install pyyaml==5.1\n",
        "\n",
        "\n",
        "! python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVer1NbTvtii",
        "outputId": "687cef55-70e5-4114-edc9-5a147fc0d005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "torch:  2.2 ; cuda:  cu121\n",
            "detectron2: 0.6\n"
          ]
        }
      ],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K6fcIotDvtii"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77B4zjJGvbgD"
      },
      "source": [
        "In order to compute mistakenness, your dataset needs to have two [detections fields](https://voxel51.com/docs/fiftyone/user_guide/using_datasets.html#object-detection), one with your ground truth annotations and one with your model predictions.\n",
        "\n",
        "In this notebook, we'll load the [clean lab 118 sample  dataset] (https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/tutorial_obj/example_images.zip) The images do not have the ground truth value, so we will extract the ground truth label from the coco_dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tKy8l7zfTZ6",
        "outputId": "f7e5e4b0-1c18-4f0d-ea35-d034808c74bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-24 17:05:32--  https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/tutorial_obj/example_images.zip\n",
            "Resolving cleanlab-public.s3.amazonaws.com (cleanlab-public.s3.amazonaws.com)... 3.5.28.75, 54.231.232.185, 3.5.25.85, ...\n",
            "Connecting to cleanlab-public.s3.amazonaws.com (cleanlab-public.s3.amazonaws.com)|3.5.28.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17340957 (17M) [application/zip]\n",
            "Saving to: â€˜example_images.zipâ€™\n",
            "\n",
            "example_images.zip  100%[===================>]  16.54M  50.9MB/s    in 0.3s    \n",
            "\n",
            "2024-03-24 17:05:33 (50.9 MB/s) - â€˜example_images.zipâ€™ saved [17340957/17340957]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download sample images from clean lab\n",
        "!wget -nc 'https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/tutorial_obj/example_images.zip' && unzip -q -o example_images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2_Vc8pcwdTi",
        "outputId": "011bfe25-a0e1-439c-c651-edcac196611d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-24 17:06:47--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.147.140, 54.231.164.201, 52.217.116.113, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.147.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: â€˜annotations_trainval2017.zipâ€™\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  90.5MB/s    in 2.7s    \n",
            "\n",
            "2024-03-24 17:06:50 (90.5 MB/s) - â€˜annotations_trainval2017.zipâ€™ saved [252907541/252907541]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#download annotations from Coco dataset\n",
        "!wget -nc http://images.cocodataset.org/annotations/annotations_trainval2017.zip && unzip -q -o annotations_trainval2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6vrTd5hqaaEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a532279-60ae-4c97-8257-d64276f295e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Migrating database to v0.23.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.migrations.runner:Migrating database to v0.23.7\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import pickle\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "import json\n",
        "import requests\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iYDtQ6X1adMJ"
      },
      "outputs": [],
      "source": [
        "# filter out the annotations for sample images and save their anotation information in a pickel file\n",
        "directory = './example_images/'\n",
        "files = os.listdir(directory)\n",
        "# Filtering only the files.\n",
        "sample_files = [f for f in files if os.path.isfile(directory+'/'+f)]\n",
        "pickle.dump(sample_files, open('sample_images.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w8WV3hrSccj4"
      },
      "outputs": [],
      "source": [
        "# List of selected image file names\n",
        "sample_image_list = pickle.load(open(\"./sample_images.pkl\", \"rb\"))\n",
        "\n",
        "# Path to the COCO annotations file\n",
        "annotations_path = './annotations/instances_val2017.json'\n",
        "\n",
        "# Load COCO annotations\n",
        "with open(annotations_path) as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Filter images and annotations\n",
        "info = coco_data['info']\n",
        "licenses = coco_data['licenses']\n",
        "filtered_images = [img for img in coco_data['images'] if img['file_name'] in sample_image_list]\n",
        "image_ids = {img['id']: img for img in filtered_images}\n",
        "filtered_annotations = [ann for ann in coco_data['annotations'] if ann['image_id'] in image_ids and ann['category_id'] in [1,3,10,47,62]]\n",
        "\n",
        "# Save filtered annotations to a new JSON file\n",
        "filtered_data = {\n",
        "    \"info\": info,\n",
        "    \"licenses\":licenses,\n",
        "    \"images\": filtered_images,\n",
        "    \"annotations\": filtered_annotations,\n",
        "    \"categories\": coco_data['categories']  # Preserve category info\n",
        "}\n",
        "with open('annotations/filtered_annotations.json', 'w') as f:\n",
        "    json.dump(filtered_data, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n3XvvBZe6SW",
        "outputId": "d34ef0ad-717e-4dd9-ccf9-2fdb3eb901d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of annotations: 118\n"
          ]
        }
      ],
      "source": [
        "# Path to the COCO annotations file\n",
        "annotations_path = './annotations/filtered_annotations.json'\n",
        "\n",
        "# Load COCO annotations\n",
        "with open(annotations_path) as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Count the number of annotations\n",
        "num_annotations = len(coco_data['images'])\n",
        "\n",
        "print(f\"Number of annotations: {num_annotations}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5cxR4TAqzMF",
        "outputId": "835f1681-acc2-4f27-91c7-4780eea70110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118/118 [5.2s elapsed, 0s remaining, 21.4 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118/118 [5.2s elapsed, 0s remaining, 21.4 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "# make dataset into fifty one format\n",
        "IMAGES_DIR = './example_images/'\n",
        "# Load COCO formatted dataset\n",
        "coco_dataset = fo.Dataset.from_dir(\n",
        "    dataset_type=fo.types.COCODetectionDataset,\n",
        "    data_path=IMAGES_DIR,\n",
        "    labels_path=\"/content/annotations/filtered_annotations.json\",\n",
        "    include_id=True,\n",
        "    name = 'cleanlab_coco_sample_dataset'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUuXxfphv7fa",
        "outputId": "add138f2-dc51-4aad-9687-0fb483394a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:        cleanlab_coco_sample_dataset\n",
            "Media type:  image\n",
            "Num samples: 118\n",
            "Persistent:  False\n",
            "Tags:        []\n",
            "Sample fields:\n",
            "    id:            fiftyone.core.fields.ObjectIdField\n",
            "    filepath:      fiftyone.core.fields.StringField\n",
            "    tags:          fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    detections:    fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    segmentations: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    coco_id:       fiftyone.core.fields.IntField\n"
          ]
        }
      ],
      "source": [
        "print(coco_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCGsRPu2vbgE",
        "outputId": "d8df8f90-50e5-4c18-ff59-587c5b7647ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Detections: {\n",
            "    'detections': [\n",
            "        <Detection: {\n",
            "            'id': '66005e6a2696b6cb5479ca38',\n",
            "            'attributes': {},\n",
            "            'tags': [],\n",
            "            'label': 'person',\n",
            "            'bounding_box': [\n",
            "                0.701359375,\n",
            "                0.3757460317460317,\n",
            "                0.07953125,\n",
            "                0.3899365079365079,\n",
            "            ],\n",
            "            'mask': None,\n",
            "            'confidence': None,\n",
            "            'index': None,\n",
            "            'supercategory': 'person',\n",
            "            'iscrowd': 0,\n",
            "        }>,\n",
            "    ],\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "# Print a sample ground truth detection\n",
        "sample = coco_dataset.first()\n",
        "print(sample.detections)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD5ZVTy1vbgE"
      },
      "source": [
        "Let's start by visualizing the dataset in the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b2Y92ojsvbgE",
        "outputId": "204e50a1-052c-477b-d9f2-f271d1d8ecac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-18ecd568-3316-4645-8cc2-9b49c929e864 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-18ecd568-3316-4645-8cc2-9b49c929e864 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-18ecd568-3316-4645-8cc2-9b49c929e864:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-18ecd568-3316-4645-8cc2-9b49c929e864 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-18ecd568-3316-4645-8cc2-9b49c929e864\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-18ecd568-3316-4645-8cc2-9b49c929e864\">\n",
              "      <button id=\"foactivate-18ecd568-3316-4645-8cc2-9b49c929e864\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Welcome to\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            "â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ•‘    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            "â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•     â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•\n",
            "â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘        â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            "â•šâ•â•     â•šâ•â•â•šâ•â•        â•šâ•â•      â•šâ•â•    â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•â•â•â•â• v0.23.7\n",
            "\n",
            "If you're finding FiftyOne helpful, here's how you can get involved:\n",
            "\n",
            "|\n",
            "|  â­â­â­ Give the project a star on GitHub â­â­â­\n",
            "|  https://github.com/voxel51/fiftyone\n",
            "|\n",
            "|  ğŸš€ğŸš€ğŸš€ Join the FiftyOne Slack community ğŸš€ğŸš€ğŸš€\n",
            "|  https://slack.voxel51.com\n",
            "|\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.core.session.session:\n",
            "Welcome to\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            "â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ•‘    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            "â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•     â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•\n",
            "â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘        â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            "â•šâ•â•     â•šâ•â•â•šâ•â•        â•šâ•â•      â•šâ•â•    â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•â•â•â•â• v0.23.7\n",
            "\n",
            "If you're finding FiftyOne helpful, here's how you can get involved:\n",
            "\n",
            "|\n",
            "|  â­â­â­ Give the project a star on GitHub â­â­â­\n",
            "|  https://github.com/voxel51/fiftyone\n",
            "|\n",
            "|  ğŸš€ğŸš€ğŸš€ Join the FiftyOne Slack community ğŸš€ğŸš€ğŸš€\n",
            "|  https://slack.voxel51.com\n",
            "|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Open the dataset in the App\n",
        "session = fo.launch_app(coco_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrvteLu7vbgF"
      },
      "source": [
        "When working with FiftyOne datasets that contain a field with `Detections`, you can create a [patches view](https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-object-patches) both through Python and directly in the FiftyOne App to view each detection as a separate sample."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Prediction to the dataset\n",
        "Model: preconfigured  "
      ],
      "metadata": {
        "id": "vjq1D2Xnc3PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# Get the metadata for the COCO dataset\n",
        "metadata = MetadataCatalog.get(\"coco_2017_train\")  # or \"coco_2017_val\", depending on your use case\n",
        "\n",
        "# Access the list of category names\n",
        "class_names = metadata.thing_classes\n",
        "\n",
        "class_to_index = {class_name: index for index, class_name in enumerate(class_names)}\n",
        "print(class_to_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZMei3c5pJeR",
        "outputId": "100ed077-60fe-402b-80b8-5c5cb5536e3d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'person': 0, 'bicycle': 1, 'car': 2, 'motorcycle': 3, 'airplane': 4, 'bus': 5, 'train': 6, 'truck': 7, 'boat': 8, 'traffic light': 9, 'fire hydrant': 10, 'stop sign': 11, 'parking meter': 12, 'bench': 13, 'bird': 14, 'cat': 15, 'dog': 16, 'horse': 17, 'sheep': 18, 'cow': 19, 'elephant': 20, 'bear': 21, 'zebra': 22, 'giraffe': 23, 'backpack': 24, 'umbrella': 25, 'handbag': 26, 'tie': 27, 'suitcase': 28, 'frisbee': 29, 'skis': 30, 'snowboard': 31, 'sports ball': 32, 'kite': 33, 'baseball bat': 34, 'baseball glove': 35, 'skateboard': 36, 'surfboard': 37, 'tennis racket': 38, 'bottle': 39, 'wine glass': 40, 'cup': 41, 'fork': 42, 'knife': 43, 'spoon': 44, 'bowl': 45, 'banana': 46, 'apple': 47, 'sandwich': 48, 'orange': 49, 'broccoli': 50, 'carrot': 51, 'hot dog': 52, 'pizza': 53, 'donut': 54, 'cake': 55, 'chair': 56, 'couch': 57, 'potted plant': 58, 'bed': 59, 'dining table': 60, 'toilet': 61, 'tv': 62, 'laptop': 63, 'mouse': 64, 'remote': 65, 'keyboard': 66, 'cell phone': 67, 'microwave': 68, 'oven': 69, 'toaster': 70, 'sink': 71, 'refrigerator': 72, 'book': 73, 'clock': 74, 'vase': 75, 'scissors': 76, 'teddy bear': 77, 'hair drier': 78, 'toothbrush': 79}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use this to find the index of five object of interest, person, car, chair, traffic light, cup\n",
        "\n",
        "class_to_index['car']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC3BqGtdqd7C",
        "outputId": "9b7505c6-84bb-4b61-8f93-ab1a54dfecda"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HsEZvLevbgF",
        "outputId": "e49e33a1-893f-4c40-dbca-3f05f729e101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     cleanlab_coco_sample_dataset\n",
            "Media type:  image\n",
            "Num patches: 326\n",
            "Patch fields:\n",
            "    id:         fiftyone.core.fields.ObjectIdField\n",
            "    sample_id:  fiftyone.core.fields.ObjectIdField\n",
            "    filepath:   fiftyone.core.fields.StringField\n",
            "    tags:       fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    detections: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detection)\n",
            "View stages:\n",
            "    1. ToPatches(field='detections', config=None)\n"
          ]
        }
      ],
      "source": [
        "patches_view = coco_dataset.to_patches(\"detections\")\n",
        "print(patches_view)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAo1MbwPvbgF"
      },
      "source": [
        "Let's open the App and click the [patches button](https://voxel51.com/docs/fiftyone/user_guide/app.html#viewing-object-patches), then select `ground_truth` to create the same view that we created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "ISZ37Op0vbgF",
        "outputId": "d7f8ba84-bbb0-45d1-f59e-3717e9b573c3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-cf5aabac-3925-4272-b910-d52ecb834c1b {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-cf5aabac-3925-4272-b910-d52ecb834c1b {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-cf5aabac-3925-4272-b910-d52ecb834c1b:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-cf5aabac-3925-4272-b910-d52ecb834c1b {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-cf5aabac-3925-4272-b910-d52ecb834c1b\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-cf5aabac-3925-4272-b910-d52ecb834c1b\">\n",
              "      <button id=\"foactivate-cf5aabac-3925-4272-b910-d52ecb834c1b\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "session = fo.launch_app(coco_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "\n",
        "\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
        "cfg.MODEL.DEVICE = 'cuda'\n",
        "model = DefaultPredictor(cfg)\n",
        "\n",
        "# # model.to(device)\n",
        "# model.eval()\n",
        "print(\"Model ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8wkq9t01TKe",
        "outputId": "ee43d088-9662-4073-c119-4a1fa5bdea8c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/24 17:16:01 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_68b088.pkl: 421MB [00:05, 79.4MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detectron_to_fo(outputs, img_w, img_h):\n",
        "    # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    detections = []\n",
        "    instances = outputs[\"instances\"].to(\"cpu\")\n",
        "    for pred_box, score, c in zip(\n",
        "        instances.pred_boxes, instances.scores, instances.pred_classes,\n",
        "    ):\n",
        "      c=c.item()\n",
        "      if c in [0,2,9,41,56]:\n",
        "        x1, y1, x2, y2 = pred_box\n",
        "        # fo_mask = mask.numpy()[int(y1):int(y2), int(x1):int(x2)]\n",
        "        bbox = [float(x1)/img_w, float(y1)/img_h, float(x2-x1)/img_w, float(y2-y1)/img_h]\n",
        "        detection = fo.Detection(label=classes[c], confidence=float(score), bounding_box=bbox)\n",
        "        detections.append(detection)\n",
        "\n",
        "    return fo.Detections(detections=detections)\n"
      ],
      "metadata": {
        "id": "xSLluz2PgXfd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision.transforms import functional as func\n",
        "\n",
        "\n",
        "# Get class list\n",
        "# classes = coco_dataset.default_classes\n",
        "classes = {0:'person', 2:'car',41:'cup',56:'chair',9:'traffic light'}\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Add predictions to samples\n",
        "with fo.ProgressBar() as pb:\n",
        "    for sample in pb(coco_dataset):\n",
        "        # Load image\n",
        "        image = cv2.imread(sample.filepath)\n",
        "        # print(image)\n",
        "        # image = func.to_tensor(image).to(device)\n",
        "        h, w, c = image.shape\n",
        "\n",
        "        outputs = model(image)\n",
        "        detections = detectron_to_fo(outputs, w, h)\n",
        "\n",
        "        # Save predictions to dataset\n",
        "        sample[\"predictions\"] = detections\n",
        "        sample.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHFY2xAi_FCD",
        "outputId": "7f55fce4-f207-4fa9-f325-b2c4a4fb2aa3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0% ||----------------|   0/118 [8.9ms elapsed, ? remaining, ? samples/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118/118 [42.0s elapsed, 0s remaining, 3.4 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118/118 [42.0s elapsed, 0s remaining, 3.4 samples/s]      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1OLm_x27De-",
        "outputId": "91512293-32d3-466e-f6b0-1f035bf94c49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:        cleanlab_coco_sample_dataset\n",
            "Media type:  image\n",
            "Num samples: 118\n",
            "Persistent:  False\n",
            "Tags:        []\n",
            "Sample fields:\n",
            "    id:            fiftyone.core.fields.ObjectIdField\n",
            "    filepath:      fiftyone.core.fields.StringField\n",
            "    tags:          fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    detections:    fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    segmentations: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    coco_id:       fiftyone.core.fields.IntField\n",
            "    predictions:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
          ]
        }
      ],
      "source": [
        "print(coco_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5f8vgkYKZU5",
        "outputId": "f6d0b39e-4805-4f39-f7b1-0b4f4f8e2b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     cleanlab_coco_sample_dataset\n",
            "Media type:  image\n",
            "Num patches: 383\n",
            "Patch fields:\n",
            "    id:          fiftyone.core.fields.ObjectIdField\n",
            "    sample_id:   fiftyone.core.fields.ObjectIdField\n",
            "    filepath:    fiftyone.core.fields.StringField\n",
            "    tags:        fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:    fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    predictions: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detection)\n",
            "View stages:\n",
            "    1. ToPatches(field='predictions', config=None)\n"
          ]
        }
      ],
      "source": [
        "predicted_view = coco_dataset.to_patches(\"predictions\")\n",
        "print(predicted_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "N5yZ5jXU7DXa",
        "outputId": "62db70af-6557-4b76-9ace-b229c38ff1cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-7e6ef4d5-0574-4384-a0fd-4a82d77feafb {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-7e6ef4d5-0574-4384-a0fd-4a82d77feafb {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-7e6ef4d5-0574-4384-a0fd-4a82d77feafb:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-7e6ef4d5-0574-4384-a0fd-4a82d77feafb {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-7e6ef4d5-0574-4384-a0fd-4a82d77feafb\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-7e6ef4d5-0574-4384-a0fd-4a82d77feafb\">\n",
              "      <button id=\"foactivate-7e6ef4d5-0574-4384-a0fd-4a82d77feafb\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "session = fo.launch_app(coco_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYsOGI26vbgG"
      },
      "source": [
        "## Compute mistakenness\n",
        "\n",
        "Now we're ready to assess the mistakenness of the ground truth detections.\n",
        "\n",
        "We can do so by running the [compute_mistakenness()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_mistakenness) method from the FiftyOne Brain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfs5CTHhvbgG",
        "outputId": "c3d9141f-4c41-4dda-c8c1-4534228ac627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.detection:Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118/118 [3.1s elapsed, 0s remaining, 31.9 samples/s]          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118/118 [3.1s elapsed, 0s remaining, 31.9 samples/s]          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing mistakenness...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.brain.internal.core.mistakenness:Computing mistakenness...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118/118 [1.7s elapsed, 0s remaining, 64.9 samples/s]          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118/118 [1.7s elapsed, 0s remaining, 64.9 samples/s]          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistakenness computation complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.brain.internal.core.mistakenness:Mistakenness computation complete\n"
          ]
        }
      ],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Compute mistakenness of annotations in `ground_truth` field using\n",
        "# predictions from `predictions` field as point of reference\n",
        "fob.compute_mistakenness(coco_dataset, \"predictions\", label_field=\"detections\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWohdHoEvbgH"
      },
      "source": [
        "The above method populates a number of fields on the samples of our dataset as well as the ground truth and predicted objects:\n",
        "\n",
        "New ground truth object attributes (in `detection` field):\n",
        "\n",
        "- `mistakenness` (float): A measure of the likelihood that a ground truth object's label is incorrect\n",
        "- `mistakenness_loc`: A measure of the likelihood that a ground truth object's localization (bounding box) is inaccurate\n",
        "- `possible_spurious`: Ground truth objects that were not matched with a predicted object and are deemed to be likely spurious annotations will have this attribute set to True\n",
        "\n",
        "New predicted object attributes (in `predictions` field):\n",
        "\n",
        "- `possible_missing`: If a highly confident prediction with no matching ground truth object is encountered, this attribute is set to True to indicate that it is a likely missing ground truth annotation\n",
        "\n",
        "Sample-level fields:\n",
        "\n",
        "- `mistakenness`: The maximum mistakenness of the ground truth objects in each sample\n",
        "- `possible_spurious`: The number of possible spurious ground truth objects in each sample\n",
        "- `possible_missing`: The number of possible missing ground truth objects in each sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZQNgzcivbgH"
      },
      "source": [
        "## Analyzing the results\n",
        "\n",
        "Let's use FiftyOne to investigate the results.\n",
        "\n",
        "First, let's show the samples with the most likely annotation mistakes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqLyVG9_vbgH",
        "outputId": "3493e515-6a0e-4699-bfed-f236079a47b1",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     cleanlab_coco_sample_dataset\n",
            "Media type:  image\n",
            "Num samples: 118\n",
            "Sample fields:\n",
            "    id:                fiftyone.core.fields.ObjectIdField\n",
            "    filepath:          fiftyone.core.fields.StringField\n",
            "    tags:              fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:          fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    detections:        fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    segmentations:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    coco_id:           fiftyone.core.fields.IntField\n",
            "    predictions:       fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    mistakenness:      fiftyone.core.fields.FloatField\n",
            "    possible_missing:  fiftyone.core.fields.IntField\n",
            "    possible_spurious: fiftyone.core.fields.IntField\n",
            "View stages:\n",
            "    1. SortBy(field_or_expr='mistakenness', reverse=True, create_index=True)\n"
          ]
        }
      ],
      "source": [
        "from fiftyone import ViewField as F\n",
        "\n",
        "# Sort by likelihood of mistake (most likely first)\n",
        "mistake_view = coco_dataset.sort_by(\"mistakenness\", reverse=True)\n",
        "\n",
        "# Print some information about the view\n",
        "print(mistake_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGGS_825vbgH",
        "outputId": "912ff5df-4a98-42d9-ced7-e19662da0d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Detection: {\n",
            "    'id': '66005e6d2696b6cb5479cc36',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'chair',\n",
            "    'bounding_box': [\n",
            "        0.56346875,\n",
            "        0.4404583333333333,\n",
            "        0.055843750000000004,\n",
            "        0.10791666666666666,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'confidence': None,\n",
            "    'index': None,\n",
            "    'supercategory': 'furniture',\n",
            "    'iscrowd': 0,\n",
            "    'mistakenness': 0.04213273525238037,\n",
            "    'mistakenness_loc': 0.20996548376646346,\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "# Inspect some samples and detections\n",
        "# This is the first detection of the first sample\n",
        "print(mistake_view.first().detections.detections[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M0mXQjrvbgH"
      },
      "source": [
        "Let's use the App to visually inspect the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "kERcfF9MvbgH",
        "outputId": "ff844e65-c0f0-4809-99b0-f33f600bd901"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-91e32909-855c-4c5e-9cdb-f0a18269be61 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-91e32909-855c-4c5e-9cdb-f0a18269be61 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-91e32909-855c-4c5e-9cdb-f0a18269be61:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-91e32909-855c-4c5e-9cdb-f0a18269be61 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-91e32909-855c-4c5e-9cdb-f0a18269be61\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-91e32909-855c-4c5e-9cdb-f0a18269be61\">\n",
              "      <button id=\"foactivate-91e32909-855c-4c5e-9cdb-f0a18269be61\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Open new App window\n",
        "session.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "CrrV2qsfvbgI",
        "outputId": "5af73dd5-ca06-48e3-9ad8-6bec09e1c55c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-7ef0a88b-9dbf-416a-8905-f32ef73d82c9 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-7ef0a88b-9dbf-416a-8905-f32ef73d82c9 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-7ef0a88b-9dbf-416a-8905-f32ef73d82c9:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-7ef0a88b-9dbf-416a-8905-f32ef73d82c9 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-7ef0a88b-9dbf-416a-8905-f32ef73d82c9\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-7ef0a88b-9dbf-416a-8905-f32ef73d82c9\">\n",
              "      <button id=\"foactivate-7ef0a88b-9dbf-416a-8905-f32ef73d82c9\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Show the samples we processed in rank order by the mistakenness\n",
        "session.view = mistake_view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFd6lriQvbgI"
      },
      "source": [
        "Another useful query is to find all objects that have a high mistakenness, lets say > 0.50:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "cZTj8gwBvbgI",
        "outputId": "87bc8ad6-76b0-4a48-c4f3-d98e7c827182"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-728b795b-52c7-4506-b063-0828f9030800 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-728b795b-52c7-4506-b063-0828f9030800 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-728b795b-52c7-4506-b063-0828f9030800:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-728b795b-52c7-4506-b063-0828f9030800 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-728b795b-52c7-4506-b063-0828f9030800\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-728b795b-52c7-4506-b063-0828f9030800\">\n",
              "      <button id=\"foactivate-728b795b-52c7-4506-b063-0828f9030800\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from fiftyone import ViewField as F\n",
        "\n",
        "session.view = coco_dataset.filter_labels(\"detections\", F(\"mistakenness\") > 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l9CeOPDvbgI"
      },
      "source": [
        "Looking through the results, we see some annotations that may be incorrect. For example, in the image below the `goat` is labeled as a `sheep`.\n",
        "\n",
        "We can use a similar workflow to look at objects that may be localized poorly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "7uHAZfrJvbgI",
        "outputId": "07ac29e2-8a2c-4c75-f2dc-c58de5da27f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-4dcab61a-ffe5-4f62-b865-1d87a60993a6 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-4dcab61a-ffe5-4f62-b865-1d87a60993a6 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-4dcab61a-ffe5-4f62-b865-1d87a60993a6:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-4dcab61a-ffe5-4f62-b865-1d87a60993a6 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-4dcab61a-ffe5-4f62-b865-1d87a60993a6\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-4dcab61a-ffe5-4f62-b865-1d87a60993a6\">\n",
              "      <button id=\"foactivate-4dcab61a-ffe5-4f62-b865-1d87a60993a6\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "session.view = coco_dataset.filter_labels(\"detections\", F(\"mistakenness_loc\") > 0.50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEzXFbDxvbgI"
      },
      "source": [
        "One of the examples that popped up from this query is shown below. The bounding box around the person on the left side of the image is shifted too far to the right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlNivCgvvbgI"
      },
      "source": [
        "The `possible_missing` field can also be useful to sort by to find instances of incorrect annotations.\n",
        "\n",
        "Similarly, `possible_spurious` can be used to find objects that the model detected that may have been missed by annotators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "7ehJm7PKvbgI",
        "outputId": "07517f71-6a70-4fc9-b8be-757557e8252b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-87630c36-13b0-4628-8d9e-87b0d2148b44 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-87630c36-13b0-4628-8d9e-87b0d2148b44 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-87630c36-13b0-4628-8d9e-87b0d2148b44:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-87630c36-13b0-4628-8d9e-87b0d2148b44 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-87630c36-13b0-4628-8d9e-87b0d2148b44\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-87630c36-13b0-4628-8d9e-87b0d2148b44\">\n",
              "      <button id=\"foactivate-87630c36-13b0-4628-8d9e-87b0d2148b44\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "session.view = coco_dataset.match(F(\"possible_missing\") > 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IisEftKfvbgJ"
      },
      "source": [
        "An example that showed up from this search is shown above. There is an `apple` that was not annotated that the model detected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ7uk3WivbgJ"
      },
      "source": [
        "## Tagging and resolution\n",
        "\n",
        "Any label or collection of labels can be tagged at any time in the sample grid or expanded sample view. In the expanded sample view, individual samples can be selected by clicking on them in the media player. We can, for example, tag this `apple` prediction as `missing` and any other predictions without an associated ground truth detection.\n",
        "\n",
        "Labels with specific tags can then be selected with [select_labels()](https://voxel51.com/docs/fiftyone/api/fiftyone.core.collections.html?highlight=select_labels#fiftyone.core.collections.SampleCollection.select_labels) stage and sent off to assist in improving the annotations with your annotation provided of choice. FiftyOne currently offers integrations for both [Labelbox](https://voxel51.com/docs/fiftyone/api/fiftyone.utils.labelbox.html) and [Scale](https://voxel51.com/docs/fiftyone/api/fiftyone.utils.scale.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEv8MpmpvbgJ"
      },
      "outputs": [],
      "source": [
        "# A dataset can be filtered to only contain labels with certain tags\n",
        "# Helpful for isolating labels with issues and sending off to an annotation provider\n",
        "missing_ground_truth = coco_dataset.select_labels(tags=\"missing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_06aCf4vbgJ"
      },
      "source": [
        "**REMEMBER**: Since you are using model predictions to guide the mistakenness process, the better your model, the more accurate the mistakenness suggestions. Additionally, using logits of confidence scores will also provide better results.\n",
        "\n",
        "We used Faster-RCNN in this example which is quite a few years old. Using EfficientDet D7 provided much better results. For example, it was easily able to find this `snowboard` labeled as `skis`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja6gaettvbgJ"
      },
      "source": [
        "![skis](https://github.com/voxel51/fiftyone/blob/v0.23.5/docs/source/tutorials/images/det_mistakenness_6.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5BpaTvfvbgJ"
      },
      "outputs": [],
      "source": [
        "session.freeze() # screenshot the active App for sharing"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}